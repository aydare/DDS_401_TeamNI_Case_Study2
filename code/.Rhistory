knitr::opts_chunk$set(echo = TRUE)
library(randomForest)
library(RCurl)
library(ggplot2)
library(nnet)
library(kableExtra)
jobURL <- getURL("https://raw.githubusercontent.com/mjwolfe91/DDS_401_TeamNI_Case_Study2/master/Data/CaseStudy2-data.csv")
jobDF <- read.csv(text=jobURL, header=TRUE)
str(jobDF)
jobDF$AgeGroup <- cut(jobDF$X.U.FEFF.Age, c(-Inf, 18, 24, 34, 44, 54, 64, Inf))
levels(jobDF$AgeGroup) <- c("<18", "18-24", "25-34", "35-44", "45-54", "55-64", "65+")
set.seed(71)
jobs.rf <- randomForest(Attrition ~ ., data=jobDF, importance=TRUE, proximity=TRUE)
print(jobs.rf)
rf.dataframe <- data.frame(round(importance(jobs.rf),2))
kable(rf.dataframe, format = "html", align = "c") %>% kable_styling(bootstrap_options = c("striped", "hover"))
jobs.mds <- cmdscale(1 - jobs.rf$proximity, eig=TRUE)
op <- par(pty="s")
pairs(cbind(jobDF[,1:4], jobs.mds$points), cex=0.6, gap=0,
col=c("red", "green", "blue")[as.numeric(jobDF$Attrition)],
main="Job Attrition Data Predictors and MDS of Proximity Based on RandomForest")
par(op)
print(jobs.mds$GOF)
varImpPlot(jobs.rf)
importanceOrder <- order(-jobs.rf$importance)
names <- rownames(jobs.rf$importance)
for (name in names)
partialPlot(jobs.rf, jobDF, eval(name), main=name, xlab=name)
knitr::opts_chunk$set(echo = TRUE)
library(randomForest)
library(ggplot2)
library(RCurl)
library(nnet)
jobURL <- getURL("https://raw.githubusercontent.com/mjwolfe91/DDS_401_TeamNI_Case_Study2/master/Data/CaseStudy2-data.csv")
jobDF <- read.csv(text=cs_url, header=TRUE)
a=c()
i=5
for (i in 3:34) {
jobs.rf3<-randomForest(Attrition ~.,data = TrainingSet, ntree=500, mtry=i, importance=TRUE)
pred_test_cs.df3<-predict(jobs.rf3,TestSet,type ="class")
a[i-2]=mean(pred_test_cs.df3==TestSet$Attrition)
}
knitr::opts_chunk$set(echo = TRUE)
library(randomForest)
library(ggplot2)
library(RCurl)
library(nnet)
jobURL <- getURL("https://raw.githubusercontent.com/mjwolfe91/DDS_401_TeamNI_Case_Study2/master/Data/CaseStudy2-data.csv")
jobDF <- read.csv(text=jobURL, header=TRUE)
str(jobDF)
jobDF$AgeGroup <- cut(jobDF$X.U.FEFF.Age, c(-Inf, 18, 24, 34, 44, 54, 64, Inf))
levels(jobDF$AgeGroup) <- c("<18", "18-24", "25-34", "35-44", "45-54", "55-64", "65+")
str(jobDF)
head(jobDF)
summary(jobDF)
set.seed(26)
train<-sample(nrow(jobDF),0.7*nrow(jobDF), replace = FALSE)
TrainingSet<-jobDF[train,]
TestSet<-jobDF[-train,]
#summary(TrainingSet)
dim(TrainingSet)
head(TrainingSet)
dim(TestSet)
head(TestSet)
jobs.rf<- randomForest(Attrition ~., data = TrainingSet,importance=TRUE)
jobs.rf
jobs.rf2<-randomForest(Attrition ~.,data = TrainingSet,ntree=500,importance=TRUE,mtry=10)
jobs.rf2
pred_rf2<-predict(jobs.rf2,TrainingSet,type = "class")
table(pred_rf2,TrainingSet$Attrition)
pred_test_cs.df<-predict(jobs.rf2,TestSet,type = "class")
mean(pred_test_cs.df==TestSet$Attrition)
table(pred_test_cs.df,TestSet$Attrition)
round(importance(jobs.rf2),2)
varImpPlot(jobs.rf,main = "Variables by Importance",pch=19,col="blue")
var_imp<- order(-jobs.rf$importance)
names<-rownames(jobs.rf$importance)
for(name in names)
partialPlot(jobs.rf,jobDF, eval(name),main = name,xlab = name)
a=c()
i=5
for (i in 3:34) {
jobs.rf3<-randomForest(Attrition ~.,data = TrainingSet, ntree=500, mtry=i, importance=TRUE)
pred_test_cs.df3<-predict(jobs.rf3,TestSet,type ="class")
a[i-2]=mean(pred_test_cs.df3==TestSet$Attrition)
}
a
plot(3:34,a,pch=19,col="steel blue",type = "o",xlab = "mtry itteration", ylab = "Accuracy %",main = "Model optimization")
